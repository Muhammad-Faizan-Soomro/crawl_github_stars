name: GitHub Crawler

on:
  workflow_dispatch:        # allows manual trigger
  schedule:
    - cron: "0 0 * * *"     # optional: run daily at midnight UTC

jobs:
  crawl-stars:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      # ----------------------------
      # 1Ô∏è‚É£ Checkout the repository
      # ----------------------------
      - name: Checkout code
        uses: actions/checkout@v5

      # ----------------------------
      # 2Ô∏è‚É£ Set up Python
      # ----------------------------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # ----------------------------
      # 3Ô∏è‚É£ Install dependencies
      # ----------------------------
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ----------------------------
      # 4Ô∏è‚É£ Wait for Postgres
      # ----------------------------
      - name: Wait for PostgreSQL to start
        run: |
          echo "‚è≥ Waiting for PostgreSQL to become available..."
          for i in {1..15}; do
            if pg_isready -h localhost -p 5432 -U postgres; then
              echo "‚úÖ PostgreSQL is ready!"
              break
            fi
            echo "PostgreSQL not ready yet... ($i/15)"
            sleep 5
          done

      # ----------------------------
      # 5Ô∏è‚É£ Initialize Database Schema
      # ----------------------------
      - name: Set up database schema
        run: |
          echo "üß± Setting up schema from setup_schema.sql..."
          psql "$DATABASE_URL" -f infrastructure/setup_schema.sql

      # ----------------------------
      # 6Ô∏è‚É£ Run Crawler (Clean Architecture)
      # ----------------------------
      - name: Run GitHub Crawler
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DATABASE_URL: ${{ secrets.DATABASE_URL || 'postgresql://postgres:postgres@localhost:5432/testdb' }}
        run: python -m app.main  # ‚úÖ entry point inside your clean architecture project


      # ----------------------------
      # 7Ô∏è‚É£ Export Collected Data to CSV
      # ----------------------------
      - name: Export repository data to CSV
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL || 'postgresql://postgres:postgres@localhost:5432/testdb' }}
        run: |
          echo "üì§ Exporting repository data..."
          psql "$DATABASE_URL" -c "\COPY repositories TO 'repositories.csv' CSV HEADER"

      # ----------------------------
      # 8Ô∏è‚É£ Upload CSV Artifact
      # ----------------------------
      - name: Upload repository CSV as artifact
        uses: actions/upload-artifact@v4
        with:
          name: github-repositories
          path: repositories.csv